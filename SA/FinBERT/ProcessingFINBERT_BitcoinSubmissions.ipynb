{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMwE1Fex4sW1rTYw3AQljtq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import torch.nn.functional as F # To apply softmax for probabilities\n","import time"],"metadata":{"id":"kSanWPZUqua6","executionInfo":{"status":"ok","timestamp":1746386296812,"user_tz":-120,"elapsed":18,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npLDdkqRoJ4S","executionInfo":{"status":"ok","timestamp":1746386299763,"user_tz":-120,"elapsed":1010,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"a292eb49-ba16-4a1a-ee78-d4a3e6e0f9bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Correct path including 'Colab Notebooks'\n","FILE_PATH = '/content/drive/MyDrive/Bitcoin_submissions_finbert_preprocessed_20250425_142802.csv'\n","\n","# Adjust the output path as well:\n","OUTPUT_FILE_PATH = '/content/drive/MyDrive/Bitcoin_submissions_finbert_preprocessed_20250425_142802_finbert_analyzed.csv'"],"metadata":{"id":"uDzihPTiqDZr","executionInfo":{"status":"ok","timestamp":1746386492240,"user_tz":-120,"elapsed":51,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# config\n","TEXT_COLUMN = 'text_to_analyze'\n","OUTPUT_FILE_PATH = FILE_PATH.replace('.csv', '_finbert_analyzed.csv')\n","MODEL_NAME = \"ProsusAI/finbert\" # Standard FinBERT model fine-tuned for financial sentiment"],"metadata":{"id":"v3DXxHJsqjur","executionInfo":{"status":"ok","timestamp":1746386494998,"user_tz":-120,"elapsed":2,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# check GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using CPU. Processing might be slow.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R90kGJm9rHfg","executionInfo":{"status":"ok","timestamp":1746386498467,"user_tz":-120,"elapsed":55,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"1cedc29a-006c-4077-a6cc-3a9be8e86a5d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# load tokenizer\n","print(f\"Loading FinBERT model ({MODEL_NAME}) and tokenizer...\")\n","try:\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","    model.to(device) # Move model to GPU if available\n","    print(\"Model and tokenizer loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading model/tokenizer: {e}\")\n","    exit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHDHaDcOrHbH","executionInfo":{"status":"ok","timestamp":1746386515412,"user_tz":-120,"elapsed":908,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"3b9df404-9a21-4a36-9aae-16b8bfd7d772"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading FinBERT model (ProsusAI/finbert) and tokenizer...\n","Model and tokenizer loaded successfully.\n"]}]},{"cell_type":"code","source":["# Add this in a new cell RIGHT BEFORE your pd.read_csv cell\n","!ls -l /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFqBfPw-t7-0","executionInfo":{"status":"ok","timestamp":1746386510170,"user_tz":-120,"elapsed":107,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"b49de7c7-b42e-4373-8ea6-3d960a45362f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["total 121745\n","-rw------- 1 root root 124653165 Apr 25 12:28  Bitcoin_submissions_finbert_preprocessed_20250425_142802.csv\n","drwx------ 3 root root      4096 Oct 24  2024 'Colab Notebooks'\n","drwx------ 2 root root      4096 Sep  6  2016  Dokumente\n","drwx------ 2 root root      4096 Sep 19  2022  GoodNotes\n","-rw------- 1 root root       172 Apr  7 19:21  thesheet.gsheet\n"]}]},{"cell_type":"code","source":["# load data\n","print(f\"\\nLoading data from: {FILE_PATH}\")\n","try:\n","    # Try detecting encoding, common ones are utf-8 and latin-1\n","    try:\n","        df = pd.read_csv(FILE_PATH)\n","    except UnicodeDecodeError:\n","        print(\"UTF-8 decoding failed, trying latin-1...\")\n","        df = pd.read_csv(FILE_PATH, encoding='latin-1')\n","\n","    print(f\"Successfully loaded {len(df)} rows.\")\n","    print(\"DataFrame head:\\n\", df.head())\n","\n","    # Verify the text column exists\n","    if TEXT_COLUMN not in df.columns:\n","        print(f\"\\nError: Column '{TEXT_COLUMN}' not found in the CSV.\")\n","        print(\"Available columns:\", df.columns.tolist())\n","        exit()\n","    # Optional: Check for missing values in the text column\n","    missing_text = df[TEXT_COLUMN].isnull().sum()\n","    if missing_text > 0:\n","        print(f\"\\nWarning: Found {missing_text} missing values in '{TEXT_COLUMN}'. These will be skipped.\")\n","        # Optionally fill NaN values if needed, e.g., df[TEXT_COLUMN].fillna('', inplace=True)\n","\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {FILE_PATH}\")\n","    exit()\n","except Exception as e:\n","    print(f\"Error loading or reading CSV: {e}\")\n","    exit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gVOQYwXrHXH","executionInfo":{"status":"ok","timestamp":1746386529513,"user_tz":-120,"elapsed":4827,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"be10c5b9-72c4-428e-e32f-12d3c83c97d7"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loading data from: /content/drive/MyDrive/Bitcoin_submissions_finbert_preprocessed_20250425_142802.csv\n","Successfully loaded 384151 rows.\n","DataFrame head:\n","          author  score                                               link  \\\n","0   u/[deleted]      0  https://www.reddit.com/r/Bitcoin/comments/ko10...   \n","1  u/randum-guy      0  https://www.reddit.com/r/Bitcoin/comments/ko12...   \n","2    u/Mari0805    119  https://www.reddit.com/r/Bitcoin/comments/ko15...   \n","3   u/[deleted]      0  https://www.reddit.com/r/Bitcoin/comments/ko17...   \n","4   u/[deleted]      1  https://www.reddit.com/r/Bitcoin/comments/ko18...   \n","\n","               created                                    text_to_analyze  \n","0  2021-01-01 01:00:00                first time saved made money deleted  \n","1  2021-01-01 01:02:00  btc dip to 20k is it possible for bitcoin to d...  \n","2  2021-01-01 01:07:00  btc just had the monthly and yearly close 2020...  \n","3  2021-01-01 01:10:00                       i believe in bitcoin deleted  \n","4  2021-01-01 01:12:00  please help me find a solution with my btc wal...  \n"]}]},{"cell_type":"code","source":["# --- Define Sentiment Analysis Function ---\n","def get_finbert_sentiment(text):\n","    \"\"\"\n","    Analyzes the sentiment of a given text using the loaded FinBERT model.\n","\n","    Args:\n","        text (str): The input text.\n","\n","    Returns:\n","        tuple: (sentiment_label, prob_positive, prob_negative, prob_neutral)\n","               Returns ('no_text', 0.0, 0.0, 0.0) for invalid input.\n","               Returns ('error', 0.0, 0.0, 0.0) if analysis fails.\n","    \"\"\"\n","    # Handle non-string or empty/NaN input\n","    if not isinstance(text, str) or pd.isna(text) or text.strip() == \"\":\n","        return 'no_text', 0.0, 0.0, 0.0\n","\n","    try:\n","        # Tokenize text - Truncate long texts (BERT has a limit, often 512 tokens)\n","        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","        inputs = {k: v.to(device) for k, v in inputs.items()} # Move inputs to the same device as the model\n","\n","        # Get predictions (run inference)\n","        with torch.no_grad(): # Disable gradient calculations for efficiency\n","            outputs = model(**inputs)\n","\n","        # Process logits (raw model output) to get probabilities and prediction\n","        logits = outputs.logits\n","        probabilities = F.softmax(logits, dim=-1).cpu() # Apply softmax and move back to CPU\n","        predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n","\n","        # Map prediction to label (FinBERT labels: 0: positive, 1: negative, 2: neutral)\n","        labels = ['positive', 'negative', 'neutral']\n","        sentiment_label = labels[predicted_class_id]\n","\n","        # Get probabilities for each class\n","        prob_positive = probabilities[0][0].item()\n","        prob_negative = probabilities[0][1].item()\n","        prob_neutral = probabilities[0][2].item()\n","\n","        return sentiment_label, prob_positive, prob_negative, prob_neutral\n","\n","    except Exception as e:\n","        # print(f\"Error processing text: '{text[:50]}...' - {e}\") # Uncomment for debugging\n","        return 'error', 0.0, 0.0, 0.0"],"metadata":{"id":"1vkVeVXjrHRB","executionInfo":{"status":"ok","timestamp":1746386533733,"user_tz":-120,"elapsed":7,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# --- Apply Sentiment Analysis ---\n","print(f\"\\nStarting FinBERT sentiment analysis on the '{TEXT_COLUMN}' column...\")\n","print(f\"Processing {len(df)} rows. This may take a while (especially on CPU)...\")\n","\n","start_time = time.time()\n","\n","# Apply the function row by row.\n","# Note: For very large datasets (> millions of rows), consider batch processing\n","# or libraries like pandarallel/Dask for speedup. For 150MB, this should be okay.\n","results = df[TEXT_COLUMN].apply(get_finbert_sentiment)\n","\n","# --- Add Results to DataFrame ---\n","# Create new columns from the tuple returned by the function\n","df[['finbert_sentiment', 'finbert_prob_positive', 'finbert_prob_negative', 'finbert_prob_neutral']] = pd.DataFrame(results.tolist(), index=df.index)\n","\n","end_time = time.time()\n","print(f\"\\nSentiment analysis complete in {end_time - start_time:.2f} seconds.\")\n","print(\"\\nDataFrame head with new sentiment columns:\\n\", df.head())\n","\n","# Display sentiment distribution\n","print(\"\\nSentiment Distribution:\")\n","print(df['finbert_sentiment'].value_counts())\n","\n","# --- Save Results ---\n","print(f\"\\nSaving results to: {OUTPUT_FILE_PATH}\")\n","try:\n","    df.to_csv(OUTPUT_FILE_PATH, index=False, encoding='utf-8-sig') # Use utf-8-sig for better Excel compatibility\n","    print(\"Results saved successfully.\")\n","except Exception as e:\n","    print(f\"Error saving results to CSV: {e}\")\n","\n","print(\"\\nScript finished.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlGSjP4orHBs","executionInfo":{"status":"ok","timestamp":1746390126348,"user_tz":-120,"elapsed":3562578,"user":{"displayName":"Leo Hubmann","userId":"17213750296793453609"}},"outputId":"9077922b-3fc5-4d0a-b92a-2d8dafc4c354"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting FinBERT sentiment analysis on the 'text_to_analyze' column...\n","Processing 384151 rows. This may take a while (especially on CPU)...\n","\n","Sentiment analysis complete in 3556.20 seconds.\n","\n","DataFrame head with new sentiment columns:\n","          author  score                                               link  \\\n","0   u/[deleted]      0  https://www.reddit.com/r/Bitcoin/comments/ko10...   \n","1  u/randum-guy      0  https://www.reddit.com/r/Bitcoin/comments/ko12...   \n","2    u/Mari0805    119  https://www.reddit.com/r/Bitcoin/comments/ko15...   \n","3   u/[deleted]      0  https://www.reddit.com/r/Bitcoin/comments/ko17...   \n","4   u/[deleted]      1  https://www.reddit.com/r/Bitcoin/comments/ko18...   \n","\n","               created                                    text_to_analyze  \\\n","0  2021-01-01 01:00:00                first time saved made money deleted   \n","1  2021-01-01 01:02:00  btc dip to 20k is it possible for bitcoin to d...   \n","2  2021-01-01 01:07:00  btc just had the monthly and yearly close 2020...   \n","3  2021-01-01 01:10:00                       i believe in bitcoin deleted   \n","4  2021-01-01 01:12:00  please help me find a solution with my btc wal...   \n","\n","  finbert_sentiment  finbert_prob_positive  finbert_prob_negative  \\\n","0           neutral               0.218316               0.015092   \n","1           neutral               0.072848               0.039153   \n","2           neutral               0.097739               0.020279   \n","3           neutral               0.054799               0.015253   \n","4           neutral               0.128142               0.011002   \n","\n","   finbert_prob_neutral  \n","0              0.766592  \n","1              0.887999  \n","2              0.881982  \n","3              0.929947  \n","4              0.860856  \n","\n","Sentiment Distribution:\n","finbert_sentiment\n","neutral     344324\n","negative     23057\n","positive     16770\n","Name: count, dtype: int64\n","\n","Saving results to: /content/drive/MyDrive/Bitcoin_submissions_finbert_preprocessed_20250425_142802_finbert_analyzed.csv\n","Results saved successfully.\n","\n","Script finished.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IuJ6Ltq7rh-V"},"execution_count":null,"outputs":[]}]}